{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/apple/Desktop/new_project_ml/once_again/textcaps/tamil_train.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/apple/Desktop/new_project_ml/once_again/textcaps/tamil_train.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/apple/Desktop/new_project_ml/once_again/textcaps/tamil_train.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/apple/Desktop/new_project_ml/once_again/textcaps/tamil_train.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(root_folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate over all subfolders in the root folder\n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "\n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            for filename in os.listdir(folder_path):\n",
    "                img = cv2.imread(os.path.join(folder_path, filename))\n",
    "                # img = cv2.resize(img, (28, 28))  # You can resize images if needed\n",
    "                if img is not None:\n",
    "                    images.append(img)\n",
    "                    labels.append(folder_name)  # Use folder name as the label\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test= load_images(\"Tamil/test\")\n",
    "X_train,y_train= load_images(\"Tamil/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test[:,:,:,0]\n",
    "X_train=X_train[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.expand_dims(X_test, axis=-1)\n",
    "X_train=np.expand_dims(X_train, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.astype(int)\n",
    "y_train = y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1572/1572 [==============================] - 54s 34ms/step - loss: 5.0507 - accuracy: 0.0083 - val_loss: 5.0495 - val_accuracy: 0.0090\n",
      "Epoch 2/50\n",
      "1572/1572 [==============================] - 58s 37ms/step - loss: 5.0504 - accuracy: 0.0090 - val_loss: 5.0494 - val_accuracy: 0.0090\n",
      "Epoch 3/50\n",
      "1572/1572 [==============================] - 61s 39ms/step - loss: 5.0504 - accuracy: 0.0090 - val_loss: 5.0494 - val_accuracy: 0.0090\n",
      "Epoch 4/50\n",
      "1572/1572 [==============================] - 104s 66ms/step - loss: 5.0504 - accuracy: 0.0090 - val_loss: 5.0494 - val_accuracy: 0.0090\n",
      "Epoch 5/50\n",
      "1572/1572 [==============================] - 79s 50ms/step - loss: 5.0504 - accuracy: 0.0090 - val_loss: 5.0494 - val_accuracy: 0.0090\n",
      "Epoch 6/50\n",
      " 131/1572 [=>............................] - ETA: 1:04 - loss: 5.0495 - accuracy: 0.0093"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/darshanrao/Main/Projects/Machine Learning/tamil_train.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/darshanrao/Main/Projects/Machine%20Learning/tamil_train.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m early_stopping \u001b[39m=\u001b[39m callbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/darshanrao/Main/Projects/Machine%20Learning/tamil_train.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Train the model with early stopping and Adam optimizer\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/darshanrao/Main/Projects/Machine%20Learning/tamil_train.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X_train, y_train, epochs\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, validation_data\u001b[39m=\u001b[39m(X_test, y_test), callbacks\u001b[39m=\u001b[39m[early_stopping])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/darshanrao/Main/Projects/Machine%20Learning/tamil_train.ipynb#X10sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Evaluate the model on the test set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/darshanrao/Main/Projects/Machine%20Learning/tamil_train.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1808\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    869\u001b[0m       args, kwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_config\n\u001b[1;32m    870\u001b[0m   )\n\u001b[1;32m    871\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_function\u001b[39m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_flat(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m   1487\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1488\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   1489\u001b[0m       inputs\u001b[39m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1490\u001b[0m       attrs\u001b[39m=\u001b[39mattrs,\n\u001b[1;32m   1491\u001b[0m       ctx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1492\u001b[0m   )\n\u001b[1;32m   1493\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Normalize pixel values to be between 0 and 1\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "# Create a simple CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(156, activation='softmax'))  \n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  # Adjust the learning rate as needed\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Train the model with early stopping and Adam optimizer\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"\\nTest accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 - 4s - loss: 5.0495 - accuracy: 0.0090 - 4s/epoch - 10ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "test_acc+= 0.955\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.9639867981150746\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTest accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14fbb8cd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_test[0,:,:,1],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12574, 64, 64, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "\n",
    "# Example NumPy array\n",
    "data = X_test[:10]\n",
    "\n",
    "# Create an ImageDataGenerator with desired augmentations\n",
    "datagen = ImageDataGenerator(\n",
    "    # rotation_range = 3,\n",
    "    width_shift_range=0.5,  # Shift images horizontally by up to 20% of the width\n",
    "    height_shift_range=0.5,  # Shift images vertically by up to 20% of the height\n",
    ")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = 'augmented_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over each image in the NumPy array\n",
    "for i, image in enumerate(data):\n",
    "    # Expand dimensions to (1, 64, 64, 1) to match ImageDataGenerator input shape\n",
    "    expanded_image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # Generate augmented images\n",
    "    augmented_images = datagen.flow(expanded_image, batch_size=1, save_to_dir=output_dir, save_prefix=f'image_{i}', save_format='jpg')\n",
    "\n",
    "    # Generate and save images\n",
    "    for j in range(1):  # Save 5 augmented images per original image\n",
    "        augmented_image = augmented_images.next()[0].astype('uint8')\n",
    "        img = Image.fromarray(np.squeeze(augmented_image), 'L')  # Convert back to 2D and to PIL Image\n",
    "        img.save(os.path.join(output_dir, f'image_{i}_augmented_{j}.jpg'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
